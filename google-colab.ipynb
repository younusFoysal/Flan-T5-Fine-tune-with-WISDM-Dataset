{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c08f1199",
   "metadata": {
    "id": "c08f1199"
   },
   "source": [
    "# FLAN-T5 Fine-tuning for WISDM Activity Recognition (Google Colab)\n",
    "\n",
    "This notebook fine-tunes FLAN-T5 on the WISDM accelerometer dataset by converting time-series sensor data into text format for sequence-to-text generation.\n",
    "\n",
    "**Before running:**\n",
    "1. Upload your WISDM dataset files to Google Drive\n",
    "2. Mount Google Drive in the notebook\n",
    "3. Update the dataset path to point to your uploaded files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a21f05",
   "metadata": {
    "id": "c1a21f05"
   },
   "source": [
    "## Step 1: Mount Google Drive and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6c2fc680",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14408,
     "status": "ok",
     "timestamp": 1763823665380,
     "user": {
      "displayName": "Md. Younus Foysal",
      "userId": "04317472875500369076"
     },
     "user_tz": -360
    },
    "id": "6c2fc680",
    "outputId": "d0b121b9-7d0a-4f28-f9ad-138e7e4cc883"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q transformers datasets torch scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef721250",
   "metadata": {
    "id": "ef721250"
   },
   "source": [
    "## Step 2: Import Libraries and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a75c7b3e",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1763823665395,
     "user": {
      "displayName": "Md. Younus Foysal",
      "userId": "04317472875500369076"
     },
     "user_tz": -360
    },
    "id": "a75c7b3e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df2ed6",
   "metadata": {
    "id": "89df2ed6"
   },
   "source": [
    "## Step 3: Load and Process WISDM Dataset\n",
    "\n",
    "### Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44e6b3d8",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1763823665414,
     "user": {
      "displayName": "Md. Younus Foysal",
      "userId": "04317472875500369076"
     },
     "user_tz": -360
    },
    "id": "44e6b3d8"
   },
   "outputs": [],
   "source": [
    "# ==================== STEP 1: Load WISDM Data ====================\n",
    "def load_wisdm_data(file_path):\n",
    "    \"\"\"\n",
    "    Load WISDM raw accelerometer data from text file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to WISDM_ar_v1.1_raw.txt\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with columns [user, activity, timestamp, x, y, z]\n",
    "    \"\"\"\n",
    "    print(\"Loading WISDM data...\")\n",
    "\n",
    "    # Read the file line by line and parse\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # Remove trailing semicolon and whitespace\n",
    "            line = line.strip().rstrip(';')\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                parts = line.split(',')\n",
    "                if len(parts) == 6:\n",
    "                    user = int(parts[0])\n",
    "                    activity = parts[1]\n",
    "                    timestamp = int(parts[2])\n",
    "                    x = float(parts[3])\n",
    "                    y = float(parts[4])\n",
    "                    z = float(parts[5])\n",
    "                    data.append([user, activity, timestamp, x, y, z])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['user', 'activity', 'timestamp', 'x', 'y', 'z'])\n",
    "    print(f\"Loaded {len(df)} sensor readings\")\n",
    "    print(f\"Activities: {df['activity'].unique()}\")\n",
    "    print(f\"Activity distribution:\\n{df['activity'].value_counts()}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4c146c56",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1763823665426,
     "user": {
      "displayName": "Md. Younus Foysal",
      "userId": "04317472875500369076"
     },
     "user_tz": -360
    },
    "id": "4c146c56"
   },
   "outputs": [],
   "source": [
    "# ==================== STEP 2: Create Sliding Windows ====================\n",
    "def create_sliding_windows(df, window_size=80, step_size=40):\n",
    "    \"\"\"\n",
    "    Create sliding windows from time-series data for each user and activity.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input dataframe with sensor readings\n",
    "        window_size (int): Number of samples per window (default: 80 ≈ 4 seconds at 20Hz)\n",
    "        step_size (int): Step size for sliding window (default: 40, 50% overlap)\n",
    "\n",
    "    Returns:\n",
    "        list: List of (window_data, activity_label) tuples\n",
    "    \"\"\"\n",
    "    print(f\"\\nCreating sliding windows (size={window_size}, step={step_size})...\")\n",
    "\n",
    "    windows = []\n",
    "\n",
    "    # Group by user and activity to maintain continuity\n",
    "    for (user, activity), group in tqdm(df.groupby(['user', 'activity'])):\n",
    "        # Sort by timestamp\n",
    "        group = group.sort_values('timestamp')\n",
    "\n",
    "        # Extract sensor values\n",
    "        sensor_data = group[['x', 'y', 'z']].values\n",
    "\n",
    "        # Create windows\n",
    "        for i in range(0, len(sensor_data) - window_size + 1, step_size):\n",
    "            window = sensor_data[i:i + window_size]\n",
    "            if len(window) == window_size:\n",
    "                windows.append((window, activity))\n",
    "\n",
    "    print(f\"Created {len(windows)} windows\")\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8652ec69",
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1763823665482,
     "user": {
      "displayName": "Md. Younus Foysal",
      "userId": "04317472875500369076"
     },
     "user_tz": -360
    },
    "id": "8652ec69"
   },
   "outputs": [],
   "source": [
    "# ==================== STEP 3: Convert Windows to Text ====================\n",
    "def window_to_text(window):\n",
    "    \"\"\"\n",
    "    Convert a numeric sensor window to text format for T5 input.\n",
    "\n",
    "    Args:\n",
    "        window (np.ndarray): Array of shape (window_size, 3) with x, y, z values\n",
    "\n",
    "    Returns:\n",
    "        str: Text representation of the window\n",
    "    \"\"\"\n",
    "    # Convert sensor readings to text format\n",
    "    # Use statistics to make input more meaningful and avoid echo patterns\n",
    "    x_vals = window[:, 0]\n",
    "    y_vals = window[:, 1]\n",
    "    z_vals = window[:, 2]\n",
    "\n",
    "    # Calculate statistics to reduce dimensionality\n",
    "    x_mean, x_std = float(np.mean(x_vals)), float(np.std(x_vals))\n",
    "    y_mean, y_std = float(np.mean(y_vals)), float(np.std(y_vals))\n",
    "    z_mean, z_std = float(np.mean(z_vals)), float(np.std(z_vals))\n",
    "\n",
    "    # Create a descriptive text input using only statistics\n",
    "    # Avoid comma-separated numbers that model might echo\n",
    "    text = (f\"Accelerometer data: \"\n",
    "            f\"x-axis mean {x_mean:.2f} std {x_std:.2f}, \"\n",
    "            f\"y-axis mean {y_mean:.2f} std {y_std:.2f}, \"\n",
    "            f\"z-axis mean {z_mean:.2f} std {z_std:.2f}. \"\n",
    "            f\"What activity is this?\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def create_text_dataset(windows):\n",
    "    \"\"\"\n",
    "    Convert windows to text dataset format for T5.\n",
    "\n",
    "    Args:\n",
    "        windows (list): List of (window_data, activity_label) tuples\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'input_text' and 'target_text' columns\n",
    "    \"\"\"\n",
    "    print(\"\\nConverting windows to text format...\")\n",
    "\n",
    "    data = []\n",
    "    for window, activity in tqdm(windows):\n",
    "        input_text = window_to_text(window)\n",
    "        # Make target more explicit for T5\n",
    "        target_text = activity.strip()\n",
    "        data.append({'input_text': input_text, 'target_text': target_text})\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Created {len(df)} text examples\")\n",
    "    print(f\"\\nSample input: {df['input_text'].iloc[0]}\")\n",
    "    print(f\"Sample target: {df['target_text'].iloc[0]}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df2ee0ca",
   "metadata": {
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1763823665546,
     "user": {
      "displayName": "Md. Younus Foysal",
      "userId": "04317472875500369076"
     },
     "user_tz": -360
    },
    "id": "df2ee0ca"
   },
   "outputs": [],
   "source": [
    "# ==================== STEP 4: Prepare Dataset for T5 ====================\n",
    "def prepare_dataset(text_df, test_size=0.2, val_size=0.1):\n",
    "    \"\"\"\n",
    "    Split data and create HuggingFace Dataset objects.\n",
    "\n",
    "    Args:\n",
    "        text_df (pd.DataFrame): DataFrame with input_text and target_text\n",
    "        test_size (float): Proportion for test set\n",
    "        val_size (float): Proportion for validation set (from training set)\n",
    "\n",
    "    Returns:\n",
    "        DatasetDict: Dictionary with train, validation, and test datasets\n",
    "    \"\"\"\n",
    "    print(\"\\nSplitting dataset...\")\n",
    "\n",
    "    # First split: train+val vs test\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        text_df, test_size=test_size, random_state=42, stratify=text_df['target_text']\n",
    "    )\n",
    "\n",
    "    # Second split: train vs val\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df, test_size=val_size, random_state=42, stratify=train_val_df['target_text']\n",
    "    )\n",
    "\n",
    "    print(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")\n",
    "\n",
    "    # Create HuggingFace datasets\n",
    "    dataset_dict = DatasetDict({\n",
    "        'train': Dataset.from_pandas(train_df, preserve_index=False),\n",
    "        'validation': Dataset.from_pandas(val_df, preserve_index=False),\n",
    "        'test': Dataset.from_pandas(test_df, preserve_index=False)\n",
    "    })\n",
    "\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87736a36",
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1763823665588,
     "user": {
      "displayName": "Md. Younus Foysal",
      "userId": "04317472875500369076"
     },
     "user_tz": -360
    },
    "id": "87736a36"
   },
   "outputs": [],
   "source": [
    "# ==================== STEP 5: Tokenization ====================\n",
    "def preprocess_function(examples, tokenizer, max_input_length=512, max_target_length=16):\n",
    "    \"\"\"\n",
    "    Tokenize input and target texts for T5.\n",
    "    T5 expects: \"task_name: input_text\"\n",
    "\n",
    "    Args:\n",
    "        examples: Batch of examples from dataset\n",
    "        tokenizer: T5 tokenizer\n",
    "        max_input_length (int): Max length for input tokens\n",
    "        max_target_length (int): Max length for target tokens\n",
    "\n",
    "    Returns:\n",
    "        dict: Tokenized inputs and labels\n",
    "    \"\"\"\n",
    "    # Add task prefix for T5\n",
    "    inputs = [\"classify activity: \" + text for text in examples['input_text']]\n",
    "    targets = examples['target_text']\n",
    "\n",
    "    # Tokenize inputs\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "    # Tokenize targets\n",
    "    labels = tokenizer(\n",
    "        targets,\n",
    "        max_length=max_target_length,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=None\n",
    "    )\n",
    "\n",
    "    # Replace padding token id with -100 so it's ignored in loss calculation\n",
    "    labels_array = np.array(labels['input_ids'])\n",
    "    labels_array[labels_array == tokenizer.pad_token_id] = -100\n",
    "    model_inputs['labels'] = labels_array.tolist()\n",
    "    \n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def tokenize_dataset(dataset_dict, tokenizer):\n",
    "    \"\"\"\n",
    "    Apply tokenization to all splits in the dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_dict (DatasetDict): Dataset with train/val/test splits\n",
    "        tokenizer: T5 tokenizer\n",
    "\n",
    "    Returns:\n",
    "        DatasetDict: Tokenized dataset\n",
    "    \"\"\"\n",
    "    print(\"\\nTokenizing dataset...\")\n",
    "\n",
    "    tokenized_datasets = dataset_dict.map(\n",
    "        lambda examples: preprocess_function(examples, tokenizer),\n",
    "        batched=True,\n",
    "        remove_columns=dataset_dict['train'].column_names\n",
    "    )\n",
    "\n",
    "    print(\"Tokenization complete!\")\n",
    "    return tokenized_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b13d72",
   "metadata": {
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1763823665642,
     "user": {
      "displayName": "Md. Younus Foysal",
      "userId": "04317472875500369076"
     },
     "user_tz": -360
    },
    "id": "e7b13d72"
   },
   "outputs": [],
   "source": [
    "# ==================== STEP 6: Fine-tune FLAN-T5 ====================\n",
    "def train_model(tokenized_datasets, model, tokenizer, output_dir='./results', num_epochs=5):\n",
    "    \"\"\"\n",
    "    Fine-tune FLAN-T5 model using HuggingFace Trainer.\n",
    "\n",
    "    Args:\n",
    "        tokenized_datasets (DatasetDict): Tokenized train/val/test data\n",
    "        model: FLAN-T5 model\n",
    "        tokenizer: T5 tokenizer\n",
    "        output_dir (str): Directory to save model checkpoints\n",
    "        num_epochs (int): Number of training epochs\n",
    "\n",
    "    Returns:\n",
    "        Seq2SeqTrainer: Trained model trainer\n",
    "    \"\"\"\n",
    "    print(\"\\nSetting up training...\")\n",
    "\n",
    "    # Data collator for dynamic padding\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        padding=True,\n",
    "        pad_to_multiple_of=8  # For better GPU utilization\n",
    "    )\n",
    "\n",
    "    def compute_metrics(eval_preds):\n",
    "        \"\"\"Compute accuracy metrics during evaluation.\"\"\"\n",
    "        predictions, labels = eval_preds\n",
    "\n",
    "        # predictions are already token IDs when predict_with_generate=True\n",
    "        # If they're logits (3D array), we need to take argmax\n",
    "        if len(predictions.shape) == 3:\n",
    "            predictions = np.argmax(predictions, axis=-1)\n",
    "        \n",
    "        # Ensure predictions are valid integers within vocabulary range\n",
    "        # Convert to int32 to prevent overflow\n",
    "        predictions = np.clip(predictions, 0, tokenizer.vocab_size - 1).astype(np.int32)\n",
    "\n",
    "        # Decode predictions and labels\n",
    "        decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "        # Replace -100 in labels as we can't decode them\n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        # Also convert labels to int32\n",
    "        labels = np.clip(labels, 0, tokenizer.vocab_size - 1).astype(np.int32)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        # Calculate exact match accuracy\n",
    "        accuracy = sum([pred.strip().lower() == label.strip().lower()\n",
    "                       for pred, label in zip(decoded_preds, decoded_labels)]) / len(decoded_preds)\n",
    "\n",
    "        return {\"accuracy\": accuracy}\n",
    "\n",
    "    # Training arguments - optimized for classification\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,  # Standard learning rate for fine-tuning\n",
    "        per_device_train_batch_size=8,  # Reduced batch size for stability\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=num_epochs,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=3,\n",
    "        predict_with_generate=True,\n",
    "        fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
    "        logging_dir=f'{output_dir}/logs',\n",
    "        logging_steps=100,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        report_to=\"none\",  # Disable wandb/tensorboard\n",
    "        seed=42,  # For reproducibility\n",
    "        gradient_accumulation_steps=2,  # Accumulate gradients for stability\n",
    "        optim=\"adafactor\"  # Use adafactor optimizer for better stability\n",
    "    )\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets['train'],\n",
    "        eval_dataset=tokenized_datasets['validation'],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    trainer.train()\n",
    "\n",
    "    print(\"\\nTraining complete!\")\n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "87c165ef",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1763823665659,
     "user": {
      "displayName": "Md. Younus Foysal",
      "userId": "04317472875500369076"
     },
     "user_tz": -360
    },
    "id": "87c165ef"
   },
   "outputs": [],
   "source": [
    "# ==================== STEP 7: Evaluate Model ====================\n",
    "def evaluate_model(trainer, tokenized_datasets, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Evaluate the fine-tuned model on test set.\n",
    "\n",
    "    Args:\n",
    "        trainer (Seq2SeqTrainer): Trained model trainer\n",
    "        tokenized_datasets (DatasetDict): Dataset with test split\n",
    "        tokenizer: T5 tokenizer\n",
    "        model: Fine-tuned model\n",
    "\n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "\n",
    "    # Evaluate\n",
    "    metrics = trainer.evaluate(eval_dataset=tokenized_datasets['test'])\n",
    "    print(f\"Test Loss: {metrics['eval_loss']:.4f}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def test_predictions(model, tokenizer, test_inputs, num_samples=5):\n",
    "    \"\"\"\n",
    "    Generate predictions for sample inputs.\n",
    "\n",
    "    Args:\n",
    "        model: Fine-tuned model\n",
    "        tokenizer: T5 tokenizer\n",
    "        test_inputs (list): List of test input texts\n",
    "        num_samples (int): Number of samples to test\n",
    "\n",
    "    Returns:\n",
    "        list: Generated predictions\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Testing predictions on sample inputs...\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    predictions = []\n",
    "    for i, input_text in enumerate(test_inputs[:num_samples]):\n",
    "        # Add task prefix to match training format\n",
    "        prefixed_input = \"classify activity: \" + input_text\n",
    "\n",
    "        # Tokenize input\n",
    "        inputs = tokenizer(\n",
    "            prefixed_input,\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=512,\n",
    "            truncation=True\n",
    "        ).to(device)\n",
    "\n",
    "        # Generate prediction with constrained decoding\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                input_ids=inputs['input_ids'],\n",
    "                attention_mask=inputs['attention_mask'],\n",
    "                max_length=16,\n",
    "                num_beams=1,\n",
    "                temperature=0.7,\n",
    "                top_p=0.9\n",
    "            )\n",
    "\n",
    "        # Decode prediction\n",
    "        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        print(f\"\\nSample {i+1}:\")\n",
    "        print(f\"Input: {input_text[:150]}...\")\n",
    "        print(f\"Predicted Activity: {prediction}\")\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c18db4",
   "metadata": {
    "id": "a2c18db4"
   },
   "source": [
    "## Step 4: Run the Main Pipeline\n",
    "\n",
    "### Configuration\n",
    "Update the `WISDM_FILE` path based on where you uploaded the WISDM dataset in Google Drive.\n",
    "For example, if you uploaded it to `/My Drive/WISDM_ar_v1.1/`, the path would be `/content/drive/My Drive/WISDM_ar_v1.1/WISDM_ar_v1.1_raw.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aedb7757",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9695058fc8aa40e58226220603619312",
      "39e3c16f85e044f18370744dddae7046",
      "dbfae80c19be4e158465cf7dd53665cc",
      "fe1e834e088a4b48afe3a8e04b6972ff",
      "7a8fcdaf379147c7b6ad9d447ae88c9e",
      "31e8ed79e01c4dd1b7ad4a2c341e5a71",
      "3daad069c9f9446f8a29f82b6434b403",
      "379c94c53ac3471992519fc116ff61de",
      "ca86ba5b396f4f3b81fa3f1f1e69e362",
      "5176b058f337492a9efc512ee01d8aed",
      "64c25a6d63114c738b6024d5b55d5865",
      "7aa55c87548c4831bb1f8f31d6e8b775",
      "d1de0dd5c1b740cab55dc3ec0631f1e4",
      "8b7892339258436481b420ebd3c1ce58",
      "2ec24b0f8ea94fa0993ab07dcd61dd2c",
      "11b1f621381d45f3bc5216bb56fdf56a",
      "06577925c0b04f3aaf8d3c7678368320",
      "d9eef5cb878c4e43b956ee5cc9389731",
      "369af25acb824ef8b4cb113dcba64ade",
      "fd106a738d8e4210ae4f0fec12a245d0",
      "a0beef247f9f4d1686336be72571bebb",
      "4d06f18d1754477c88a02b198211069e",
      "06fec14e991646069c2d02a8c3cc9eb6",
      "90b4256755194cd1958f502c0d54c0f4",
      "b3107279a1e441039ce8740090a33b0e",
      "9dceaebb342e48dc80e352a5e0292988",
      "49140981c6f5476a93396348d088c7d7",
      "9cdd8e3431d343a58ca68bfaf58a1316",
      "ca6c2819231d45369e737f3584abc283",
      "0c72183079e7439682f248af092ee74c",
      "299e22cf1a004ef48aa38d0fcaf6dddc",
      "ea4c29277c5442c7a3dd13a44a65af7d",
      "f7f9dc57eb304d10ab3ac0bf614b300a"
     ]
    },
    "executionInfo": {
     "elapsed": 599938,
     "status": "error",
     "timestamp": 1763824265631,
     "user": {
      "displayName": "Md. Younus Foysal",
      "userId": "04317472875500369076"
     },
     "user_tz": -360
    },
    "id": "aedb7757",
    "outputId": "f9e14da5-bdf2-4b10-86b4-05ea71a37d56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FLAN-T5 Fine-tuning for WISDM Activity Recognition\n",
      "============================================================\n",
      "Loading WISDM data...\n",
      "Loaded 1086465 sensor readings\n",
      "Activities: ['Jogging' 'Walking' 'Upstairs' 'Downstairs' 'Sitting' 'Standing']\n",
      "Activity distribution:\n",
      "activity\n",
      "Walking       418393\n",
      "Jogging       336445\n",
      "Upstairs      122869\n",
      "Downstairs    100425\n",
      "Sitting        59939\n",
      "Standing       48394\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Creating sliding windows (size=80, step=40)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179/179 [00:00<00:00, 219.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 26893 windows\n",
      "\n",
      "Converting windows to text format...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26893/26893 [00:04<00:00, 6358.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 26893 text examples\n",
      "\n",
      "Sample input: Accelerometer data: x-axis mean -1.79 std 3.26, y-axis mean 9.81 std 4.16, z-axis mean 2.38 std 4.43. What activity is this?\n",
      "Sample target: Downstairs\n",
      "\n",
      "Splitting dataset...\n",
      "Train: 19362, Validation: 2152, Test: 5379\n",
      "\n",
      "Loading FLAN-T5 model: google/flan-t5-small...\n",
      "Using device: cuda\n",
      "\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9695058fc8aa40e58226220603619312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19362 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa55c87548c4831bb1f8f31d6e8b775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2152 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06fec14e991646069c2d02a8c3cc9eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5379 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete!\n",
      "\n",
      "Setting up training...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-107622200.py:72: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1212' max='6055' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1212/6055 07:58 < 31:53, 2.53 it/s, Epoch 1/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 01:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OverflowError",
     "evalue": "out of range integral type conversion attempted",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1827760151.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Step 7: Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     trainer = train_model(\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mtokenized_datasets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-107622200.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(tokenized_datasets, model, tokenizer, output_dir, num_epochs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining complete!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2326\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2790\u001b[0;31m             self._maybe_log_save_evaluate(\n\u001b[0m\u001b[1;32m   2791\u001b[0m                 \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[0m\n\u001b[1;32m   3219\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m             \u001b[0mis_new_best_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_determine_best_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_scheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer_seq2seq.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gen_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     def predict(\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4488\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4489\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4490\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4491\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4778\u001b[0m             \u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"losses\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_losses\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"loss\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4779\u001b[0m             \u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_inputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"inputs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minclude_for_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4780\u001b[0;31m             metrics = self.compute_metrics(\n\u001b[0m\u001b[1;32m   4781\u001b[0m                 \u001b[0mEvalPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0meval_set_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4782\u001b[0m             )\n",
      "\u001b[0;32m/tmp/ipython-input-107622200.py\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(eval_preds)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Decode predictions and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mdecoded_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Replace -100 in labels as we can't decode them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_decode\u001b[0;34m(self, sequences, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3883\u001b[0m         \"\"\"\n\u001b[1;32m   3884\u001b[0m         return [\n\u001b[0;32m-> 3885\u001b[0;31m             self.decode(\n\u001b[0m\u001b[1;32m   3886\u001b[0m                 \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3887\u001b[0m                 \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3922\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_py_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3924\u001b[0;31m         return self._decode(\n\u001b[0m\u001b[1;32m   3925\u001b[0m             \u001b[0mtoken_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3926\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         clean_up_tokenization_spaces = (\n",
      "\u001b[0;31mOverflowError\u001b[0m: out of range integral type conversion attempted"
     ]
    }
   ],
   "source": [
    "# ==================== MAIN PIPELINE ====================\n",
    "print(\"=\"*60)\n",
    "print(\"FLAN-T5 Fine-tuning for WISDM Activity Recognition\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Configuration\n",
    "# UPDATE THESE PATHS BASED ON YOUR GOOGLE DRIVE STRUCTURE\n",
    "# If you uploaded to /My Drive/, use: /content/drive/My\\ Drive/WISDM_ar_v1.1/WISDM_ar_v1.1_raw.txt\n",
    "WISDM_FILE = \"/content/drive/MyDrive/SIU/Flan-T5/WISDM_ar_v1.1/WISDM_ar_v1.1_raw.txt\"\n",
    "MODEL_NAME = \"google/flan-t5-small\"  # Using small version for faster training\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/SIU/Flan-T5/flan-t5-wisdm\"\n",
    "WINDOW_SIZE = 80  # ~4 seconds at 20Hz\n",
    "STEP_SIZE = 40    # 50% overlap\n",
    "NUM_EPOCHS = 5    # Increased epochs for better training\n",
    "\n",
    "# Check if WISDM data exists\n",
    "if not os.path.exists(WISDM_FILE):\n",
    "    print(f\"Error: WISDM data file not found at {WISDM_FILE}\")\n",
    "    print(\"Please ensure the WISDM dataset is uploaded to Google Drive at the specified path.\")\n",
    "    print(f\"Current file path: {WISDM_FILE}\")\n",
    "else:\n",
    "    # Step 1: Load WISDM data\n",
    "    df = load_wisdm_data(WISDM_FILE)\n",
    "\n",
    "    # Optionally limit data for faster training (remove for full dataset)\n",
    "    # df = df.groupby('activity').head(10000)\n",
    "\n",
    "    # Step 2: Create sliding windows\n",
    "    windows = create_sliding_windows(df, window_size=WINDOW_SIZE, step_size=STEP_SIZE)\n",
    "\n",
    "    # Step 3: Convert to text dataset\n",
    "    text_df = create_text_dataset(windows)\n",
    "\n",
    "    # Optionally limit dataset size for demonstration (remove for full training)\n",
    "    # text_df = text_df.groupby('target_text').head(500)\n",
    "\n",
    "    # Step 4: Prepare train/val/test splits\n",
    "    dataset_dict = prepare_dataset(text_df)\n",
    "\n",
    "    # Step 5: Load model and tokenizer\n",
    "    print(f\"\\nLoading FLAN-T5 model: {MODEL_NAME}...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Step 6: Tokenize dataset\n",
    "    tokenized_datasets = tokenize_dataset(dataset_dict, tokenizer)\n",
    "\n",
    "    # Step 7: Train model\n",
    "    trainer = train_model(\n",
    "        tokenized_datasets,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        num_epochs=NUM_EPOCHS\n",
    "    )\n",
    "\n",
    "    # Step 8: Evaluate model\n",
    "    metrics = evaluate_model(trainer, tokenized_datasets, tokenizer, model)\n",
    "\n",
    "    # Step 9: Test predictions on samples\n",
    "    test_inputs = [dataset_dict['test'][i]['input_text'] for i in range(min(5, len(dataset_dict['test'])))]\n",
    "    test_targets = [dataset_dict['test'][i]['target_text'] for i in range(min(5, len(dataset_dict['test'])))]\n",
    "\n",
    "    predictions = test_predictions(model, tokenizer, test_inputs)\n",
    "\n",
    "    # Print accuracy on test samples\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Sample Predictions vs Ground Truth:\")\n",
    "    print(\"=\"*60)\n",
    "    correct = 0\n",
    "    for i, (pred, target) in enumerate(zip(predictions, test_targets)):\n",
    "        match = pred.strip().lower() == target.strip().lower()\n",
    "        if match:\n",
    "            correct += 1\n",
    "        print(f\"Sample {i+1}: Predicted='{pred.strip()}' | Actual='{target.strip()}' | Match={match}\")\n",
    "\n",
    "    accuracy = (correct / len(predictions)) * 100 if predictions else 0\n",
    "    print(f\"\\nSample Accuracy: {accuracy:.1f}%\")\n",
    "\n",
    "    # Save final model\n",
    "    print(f\"\\nSaving final model to {OUTPUT_DIR}/final_model...\")\n",
    "    trainer.save_model(f\"{OUTPUT_DIR}/final_model\")\n",
    "    tokenizer.save_pretrained(f\"{OUTPUT_DIR}/final_model\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"PIPELINE COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Model saved to: {OUTPUT_DIR}/final_model\")\n",
    "    print(\"You can now use this model for activity recognition from accelerometer data.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06577925c0b04f3aaf8d3c7678368320": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06fec14e991646069c2d02a8c3cc9eb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_90b4256755194cd1958f502c0d54c0f4",
       "IPY_MODEL_b3107279a1e441039ce8740090a33b0e",
       "IPY_MODEL_9dceaebb342e48dc80e352a5e0292988"
      ],
      "layout": "IPY_MODEL_49140981c6f5476a93396348d088c7d7"
     }
    },
    "0c72183079e7439682f248af092ee74c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11b1f621381d45f3bc5216bb56fdf56a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "299e22cf1a004ef48aa38d0fcaf6dddc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2ec24b0f8ea94fa0993ab07dcd61dd2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0beef247f9f4d1686336be72571bebb",
      "placeholder": "​",
      "style": "IPY_MODEL_4d06f18d1754477c88a02b198211069e",
      "value": " 2152/2152 [00:02&lt;00:00, 944.25 examples/s]"
     }
    },
    "31e8ed79e01c4dd1b7ad4a2c341e5a71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "369af25acb824ef8b4cb113dcba64ade": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "379c94c53ac3471992519fc116ff61de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39e3c16f85e044f18370744dddae7046": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31e8ed79e01c4dd1b7ad4a2c341e5a71",
      "placeholder": "​",
      "style": "IPY_MODEL_3daad069c9f9446f8a29f82b6434b403",
      "value": "Map: 100%"
     }
    },
    "3daad069c9f9446f8a29f82b6434b403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49140981c6f5476a93396348d088c7d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d06f18d1754477c88a02b198211069e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5176b058f337492a9efc512ee01d8aed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64c25a6d63114c738b6024d5b55d5865": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7a8fcdaf379147c7b6ad9d447ae88c9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7aa55c87548c4831bb1f8f31d6e8b775": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d1de0dd5c1b740cab55dc3ec0631f1e4",
       "IPY_MODEL_8b7892339258436481b420ebd3c1ce58",
       "IPY_MODEL_2ec24b0f8ea94fa0993ab07dcd61dd2c"
      ],
      "layout": "IPY_MODEL_11b1f621381d45f3bc5216bb56fdf56a"
     }
    },
    "8b7892339258436481b420ebd3c1ce58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_369af25acb824ef8b4cb113dcba64ade",
      "max": 2152,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fd106a738d8e4210ae4f0fec12a245d0",
      "value": 2152
     }
    },
    "90b4256755194cd1958f502c0d54c0f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9cdd8e3431d343a58ca68bfaf58a1316",
      "placeholder": "​",
      "style": "IPY_MODEL_ca6c2819231d45369e737f3584abc283",
      "value": "Map: 100%"
     }
    },
    "9695058fc8aa40e58226220603619312": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_39e3c16f85e044f18370744dddae7046",
       "IPY_MODEL_dbfae80c19be4e158465cf7dd53665cc",
       "IPY_MODEL_fe1e834e088a4b48afe3a8e04b6972ff"
      ],
      "layout": "IPY_MODEL_7a8fcdaf379147c7b6ad9d447ae88c9e"
     }
    },
    "9cdd8e3431d343a58ca68bfaf58a1316": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9dceaebb342e48dc80e352a5e0292988": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea4c29277c5442c7a3dd13a44a65af7d",
      "placeholder": "​",
      "style": "IPY_MODEL_f7f9dc57eb304d10ab3ac0bf614b300a",
      "value": " 5379/5379 [00:04&lt;00:00, 1110.04 examples/s]"
     }
    },
    "a0beef247f9f4d1686336be72571bebb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3107279a1e441039ce8740090a33b0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c72183079e7439682f248af092ee74c",
      "max": 5379,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_299e22cf1a004ef48aa38d0fcaf6dddc",
      "value": 5379
     }
    },
    "ca6c2819231d45369e737f3584abc283": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ca86ba5b396f4f3b81fa3f1f1e69e362": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d1de0dd5c1b740cab55dc3ec0631f1e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06577925c0b04f3aaf8d3c7678368320",
      "placeholder": "​",
      "style": "IPY_MODEL_d9eef5cb878c4e43b956ee5cc9389731",
      "value": "Map: 100%"
     }
    },
    "d9eef5cb878c4e43b956ee5cc9389731": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dbfae80c19be4e158465cf7dd53665cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_379c94c53ac3471992519fc116ff61de",
      "max": 19362,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ca86ba5b396f4f3b81fa3f1f1e69e362",
      "value": 19362
     }
    },
    "ea4c29277c5442c7a3dd13a44a65af7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7f9dc57eb304d10ab3ac0bf614b300a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd106a738d8e4210ae4f0fec12a245d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe1e834e088a4b48afe3a8e04b6972ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5176b058f337492a9efc512ee01d8aed",
      "placeholder": "​",
      "style": "IPY_MODEL_64c25a6d63114c738b6024d5b55d5865",
      "value": " 19362/19362 [00:12&lt;00:00, 1797.66 examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
